#!/usr/bin/env python

import sys
import rospy
import cv2
import tf2_ros
import struct

from std_msgs.msg import String
from sensor_msgs.msg import Image, CameraInfo, PointCloud2
from sensor_msgs import point_cloud2
from cv_bridge import CvBridge, CvBridgeError
from geometry_msgs.msg import Pose, Point, TransformStamped, Vector3, Quaternion, Transform
from image_geometry import PinholeCameraModel
from tf.transformations import quaternion_from_euler

class FaceDetection:

    def __init__(self):

        # Load cascade configuration files
        # (currently saved in same directory as the node, to be moved into config)
        # self.faceCascade = cv2.CascadeClassifier("face_cascade.xml")
        self.faceCascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

        # Initialize CvBridge object, which allows conversion between ROS message
        # and OpenCV Image data type
        self.bridge = CvBridge()

        # Initialize subscriber, reading a ROS Image message type
        # (the topic will be published by the RealSense or the rosbag capture)
        self.image_sub = rospy.Subscriber('/camera/color/image_raw',
                                          Image,
                                          self.image_callback)
        self.depth_sub = rospy.Subscriber('/camera/aligned_depth_to_color/image_raw',
                                          Image,
                                          self.depth_callback)
        self.state_sub = rospy.Subscriber('state', String, self.state_callback)
        self.camera_info_sub = rospy.Subscriber('/camera/color/camera_info',  # same as /camera/aligned_depth_to_color/image_raw
                                                CameraInfo,
                                                self.camera_info_callback)
        self.pose_pub = rospy.Publisher('face_pose', Pose, queue_size=10)

        self.rate = rospy.Rate(100)

        self.state = None
        self.camera_info = None

        self.forehead_x = None  # x pixel location of forehead
        self.forehead_y = None  # y pixel location of forehead
        self.forehead_depth = None  # depth of location of forehead

        self.face_pose = None

        self.tf_broadcaster = tf2_ros.TransformBroadcaster()
        self.tf_listener = tf2_ros.TransformListener(tf2_ros.Buffer())

        # Initialize variables needed for face detection loop
        self.dx = []
        self.dy = []
        self.lockonThreshold = 2   # Pixel hysteresis
        self.nSamples = 15         # Number of samples to track
        self.lastX = 0
        self.lastY = 0

    def state_callback(self, data):
        """ Used as the 'state' callback.

            Args:
               data (std_msgs/String): the current state
        """
        self.state = data.data

    def image_callback(self, data):
        """
        Callback for image subscriber
        """

        # Attempt to pull frame from ROS message
        try:
            # Pull image as an 8-bit RGB image
            self.incomingFrame = self.bridge.imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            # Print error if incoming frame cannot be pulled
            print(e)

        # TODO: publish image with cv2 rectangles?
        # self.image_pub.publish(self.bridge.cv2_to_imgmsg(self.incomingFrame, "bgr8"))

        # Our operations on the frame come here
        # Use OpenCV to convert the incoming frame into a grayscale frame
        self.grayFrame = cv2.cvtColor(self.incomingFrame, cv2.COLOR_BGR2GRAY)

        # Run the face cascade and look for faces, then output the number of faces found
        self.faces = self.faceCascade.detectMultiScale(self.grayFrame, 1.3, 10)

        # Iterate over detected faces and draw a frame around each
        for (x, y, w, h) in self.faces:

            # Check length of dx and pop earliest element
            if len(self.dx) > self.nSamples:
                self.dx.pop(0)
            if len(self.dy) > self.nSamples:
                self.dy.pop(0)

            # Check if face has stabilized
            self.dx.append(abs(x - self.lastX))
            self.dy.append(abs(y - self.lastY))

            # Find average over last 10 frames
            self.dxAverage = sum(self.dx)/len(self.dx)
            self.dyAverage = sum(self.dy)/len(self.dy)

            # Draw a blue frame
            if (self.dxAverage < self.lockonThreshold) and \
                    (self.dxAverage < self.lockonThreshold):

                # print("LOCK-ON ACHIEVED!")

                # cv2.rectangle(self.incomingFrame, (x, y), (x+w, y+h),
                #               (0, 0, 255), 4)

                self.forehead_x = int(round(x + w/2))
                self.forehead_y = int(round(y + h/3))

                if self.forehead_depth:

                    p = PinholeCameraModel()
                    p.fromCameraInfo(self.camera_info)

                    i, j, k = p.projectPixelTo3dRay((self.forehead_x,
                                                    self.forehead_y))

                    qbr = quaternion_from_euler(-0.02411003990034436, 0.015157312816261046, -1.5709156841120222)

                    Tbr = Transform(
                            translation=Vector3(            # TODO: get this from config file later
                                x=-0.00021313403086664937,
                                y=0.026511040266107982,
                                z=1.5330730545276134),
                            rotation=Quaternion(
                                # x=-0.013147972865170205,
                                # y=0.013809048846600454,
                                # z=-0.005702271764183202,
                                # w=0.6967896267443657
                                x=qbr[0],
                                y=qbr[1],
                                z=qbr[2],
                                w=qbr[3]
                            ))
                    Tbr_stamped = TransformStamped()
                    Tbr_stamped.header.stamp = rospy.Time.now()
                    Tbr_stamped.header.frame_id = "head_camera"
                    Tbr_stamped.child_frame_id = "camera_aligned_depth_to_color_frame"
                    Tbr_stamped.transform = Tbr

                    Trf = Transform(
                            translation=Vector3(
                                x=self.forehead_depth * k,
                                y=self.forehead_depth * -i,
                                z=self.forehead_depth * -j),
                            rotation=Quaternion(
                                x=0,
                                y=0,
                                z=0,
                                w=1
                            ))
                    Trf_stamped = TransformStamped()
                    Trf_stamped.header.stamp = rospy.Time.now()
                    Trf_stamped.header.frame_id = "camera_aligned_depth_to_color_frame"
                    Trf_stamped.child_frame_id = "face"
                    Trf_stamped.transform = Trf

                    self.tf_broadcaster.sendTransform(Tbr_stamped)
                    self.tf_broadcaster.sendTransform(Trf_stamped)

                    print(Trf_stamped)

                    # Twf = self.tf_listener.lookupTransform('/face', '/world', rospy.Time(0))

                    # print(Twf)

                    # Tbf = Tbr * Trf

                    # Twb = self.tf_listener.lookupTransform('/head_camera', '/world', rospy.Time(0))

                    # Twf = Twb * Tbf

                    # print(Twf)

                    # Twf_stamped = TransformStamped()

                    # Twf_stamped.header.stamp = rospy.Time.now()
                    # Twf_stamped.header.frame_id = "world"
                    # Twf_stamped.child_frame_id = "face"
                    # Twf_stamped.transform = Twf

                    # self.tf_broadcaster.sendTransform(Twf_stamped)

                    # face_pose = Pose(position=Point(x=self.forehead_depth * k,
                    #                                 y=self.forehead_depth * -i,
                    #                                 z=self.forehead_depth * -j))

                    # # print(face_pose)

                    # face_transform = TransformStamped()

                    # face_transform.header.stamp = rospy.Time.now()
                    # face_transform.header.frame_id = "camera_aligned_depth_to_color_frame"
                    # face_transform.child_frame_id = "face"
                    # face_transform.transform.translation.x = face_pose.position.x
                    # face_transform.transform.translation.y = face_pose.position.y
                    # face_transform.transform.translation.z = face_pose.position.z
                    # face_transform.transform.rotation.x = 0
                    # face_transform.transform.rotation.y = 0
                    # face_transform.transform.rotation.z = 0
                    # face_transform.transform.rotation.w = 1

                    # self.tf_broadcaster.sendTransform(t)

            else:
                # cv2.rectangle(self.incomingFrame, (x, y), (x+w, y+h), (255, 0, 0),
                #             2)

                self.forehead_x = None
                self.forehead_y = None

            self.lastX = x
            self.lastY = y

        # # # Display the image on the screen
        # cv2.imshow("Image window", self.incomingFrame)
        # cv2.waitKey(1)

    def depth_callback(self, data):

        # Attempt to pull frame from ROS message
        try:
            # Pull image as an 8-bit RGB image
            self.incomingFrame = self.bridge.imgmsg_to_cv2(
                data, desired_encoding="passthrough")
        except CvBridgeError as e:
            # Print error if incoming frame cannot be pulled
            print(e)

        if self.forehead_x and self.forehead_y:

            self.forehead_depth = self.incomingFrame[self.forehead_y,
                                                     self.forehead_x] / 1000  # TODO

    def camera_info_callback(self, data):

        self.camera_info = data


def main(args):
    rospy.init_node('face_detection')
    find_faces = FaceDetection()
    try:
        # find_faces.loop()
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")
    cv2.destroyAllWindows()


if __name__ == '__main__':
    main(sys.argv)
