#!/usr/bin/env python

import sys
import rospy
import cv2
import tf2_ros

from std_msgs.msg import String
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge, CvBridgeError
from geometry_msgs.msg import Pose, Point, TransformStamped
from image_geometry import PinholeCameraModel

class FaceDetection:

    def __init__(self):

        # Load cascade configuration files
        # (currently saved in same directory as the node, to be moved into config)
        # self.faceCascade = cv2.CascadeClassifier("face_cascade.xml")
        self.faceCascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

        # Initialize CvBridge object, which allows conversion between ROS message
        # and OpenCV Image data type
        self.bridge = CvBridge()

        # Initialize subscriber, reading a ROS Image message type
        # (the topic will be published by the RealSense or the rosbag capture)
        self.image_sub = rospy.Subscriber('/camera/color/image_raw',
                                          Image,
                                          self.image_callback)
        self.depth_sub = rospy.Subscriber('/camera/depth/image_rect_raw',
                                          Image,
                                          self.depth_callback)
        self.state_sub = rospy.Subscriber('state', String, self.state_callback)
        self.camera_info_sub = rospy.Subscriber('/camera/color/camera_info',
                                                CameraInfo,
                                                self.camera_info_callback)
        self.pose_pub = rospy.Publisher('face_pose', Pose, queue_size=10)

        self.rate = rospy.Rate(100)

        self.state = None
        self.camera_info = None

        self.forehead_x = None  # x pixel location of forehead
        self.forehead_y = None  # y pixel location of forehead
        self.forehead_depth = None  # depth of location of forehead

        # Initialize variables needed for face detection loop
        self.dx = []
        self.dy = []
        self.lockonThreshold = 2   # Pixel hysteresis
        self.nSamples = 15         # Number of samples to track
        self.lastX = 0
        self.lastY = 0

    def state_callback(self, data):
        """ Used as the 'state' callback.

            Args:
               data (std_msgs/String): the current state
        """
        self.state = data.data

    def image_callback(self, data):
        """
        Callback for image subscriber
        """

        # Attempt to pull frame from ROS message
        try:
            # Pull image as an 8-bit RGB image
            self.incomingFrame = self.bridge.imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            # Print error if incoming frame cannot be pulled
            print(e)

        # TODO: publish image with cv2 rectangles?
        # self.image_pub.publish(self.bridge.cv2_to_imgmsg(self.incomingFrame, "bgr8"))

        # Our operations on the frame come here
        # Use OpenCV to convert the incoming frame into a grayscale frame
        self.grayFrame = cv2.cvtColor(self.incomingFrame, cv2.COLOR_BGR2GRAY)

        # Run the face cascade and look for faces, then output the number of faces found
        self.faces = self.faceCascade.detectMultiScale(self.grayFrame, 1.3, 10)

        # Iterate over detected faces and draw a frame around each
        for (x, y, w, h) in self.faces:

            # Check length of dx and pop earliest element
            if len(self.dx) > self.nSamples:
                self.dx.pop(0)
            if len(self.dy) > self.nSamples:
                self.dy.pop(0)

            # Check if face has stabilized
            self.dx.append(abs(x - self.lastX))
            self.dy.append(abs(y - self.lastY))

            # Find average over last 10 frames
            self.dxAverage = sum(self.dx)/len(self.dx)
            self.dyAverage = sum(self.dy)/len(self.dy)

            # Draw a blue frame
            if (self.dxAverage < self.lockonThreshold) and \
                    (self.dxAverage < self.lockonThreshold):

                # print("LOCK-ON ACHIEVED!")

                # cv2.rectangle(self.incomingFrame, (x, y), (x+w, y+h),
                #               (0, 0, 255), 4)

                self.forehead_x = int(round(x + w/2))
                self.forehead_y = int(round(y + h/3))

            else:
                # cv2.rectangle(self.incomingFrame, (x, y), (x+w, y+h), (255, 0, 0),
                #             2)

                self.forehead_x = None
                self.forehead_y = None

            self.lastX = x
            self.lastY = y

        # # Display the image on the screen
        # cv2.imshow("Image window", self.incomingFrame)
        # cv2.waitKey(1)

    def depth_callback(self, data):

        # Attempt to pull frame from ROS message
        try:
            # Pull image as an 8-bit RGB image
            self.incomingFrame = self.bridge.imgmsg_to_cv2(
                data, desired_encoding="passthrough")
        except CvBridgeError as e:
            # Print error if incoming frame cannot be pulled
            print(e)

        if self.forehead_x and self.forehead_y:

            self.forehead_depth = self.incomingFrame[self.forehead_x,
                                                     self.forehead_y] / 1000

        else:
            self.forehead_depth = None

    def camera_info_callback(self, data):

        self.camera_info = data

    def loop(self):

        while not rospy.is_shutdown():

            if self.forehead_x and self.forehead_y and self.forehead_depth:

                p = PinholeCameraModel()
                p.fromCameraInfo(self.camera_info)

                i, j, k = p.projectPixelTo3dRay((self.forehead_x,
                                                self.forehead_y))

                face_pose = Pose(position=Point(x=self.forehead_depth * k,
                                                y=self.forehead_depth * i,
                                                z=self.forehead_depth * -j))

                print(face_pose)

                br = tf2_ros.TransformBroadcaster()
                t = TransformStamped()

                t.header.stamp = rospy.Time.now()
                t.header.frame_id = "camera_link"
                t.child_frame_id = "face"
                t.transform.translation.x = face_pose.position.x
                t.transform.translation.y = face_pose.position.y
                t.transform.translation.z = face_pose.position.z
                t.transform.rotation.x = 0
                t.transform.rotation.y = 0
                t.transform.rotation.z = 0
                t.transform.rotation.w = 1

                br.sendTransform(t)

                # if self.state == "MOVE_TO_FACE":

                #     face_pose = Pose()
                #     face_pose.x =   # TODO

                #     self.pose_pub.publish(face_pose)

        self.rate.sleep()


def main(args):
    rospy.init_node('face_detection', anonymous=True)
    find_faces = FaceDetection()
    try:
        find_faces.loop()
        # rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")
    cv2.destroyAllWindows()


if __name__ == '__main__':
    main(sys.argv)
